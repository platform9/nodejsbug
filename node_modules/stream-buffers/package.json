{
  "name": "stream-buffers",
  "version": "3.0.0",
  "description": "Buffer-backed Streams for reading and writing.",
  "keywords": [
    "memory streams",
    "streams",
    "buffer streams"
  ],
  "author": {
    "name": "Sam Day",
    "email": "me@samcday.com.au"
  },
  "main": "./lib/streambuffer.js",
  "engines": {
    "node": ">= 0.10.0"
  },
  "dependencies": {},
  "devDependencies": {
    "chai": "^3.4.1",
    "eslint": "^1.9.0",
    "istanbul": "^0.4.0",
    "mocha": "^2.3.4"
  },
  "license": "Unlicense",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/samcday/node-stream-buffer.git"
  },
  "scripts": {
    "test": "istanbul test _mocha",
    "lint": "eslint ."
  },
  "readme": "# Node Stream Buffers\r\n\r\n[![Build Status][badge-travis-img]][badge-travis-url]\r\n[![Dependency Information][badge-david-img]][badge-david-url]\r\n[![Code Climate][badge-climate-img]][badge-climate-url]\r\n[![Code Coverage][badge-coverage-img]][badge-coverage-url]\r\n[![npm][badge-npm-img]][badge-npm-url]\r\n\r\nSimple Readable and Writable Streams that use a [Buffer][node-buffer-docs] to store received data, or for data to send out. Useful for test code, debugging, and a wide range of other utilities.\r\n\r\n```\r\nnpm install stream-buffers --save\r\n```\r\n\r\n## Usage\r\n\r\nTo use the stream buffers in your module, simply import it and away you go.\r\n\r\n```js\r\nvar streamBuffers = require('stream-buffers');\r\n```\r\n\r\n### WritableStreamBuffer\r\n\r\n`WritableStreamBuffer` implements the standard [`stream.Writable`](https://nodejs.org/api/stream.html#stream_class_stream_writable) interface. All writes to this stream will accumulate in an internal [`Buffer`](https://nodejs.org/api/buffer.html). If the internal buffer overflows it will be resized automatically. The initial size of the Buffer and the amount in which it grows can be configured in the constructor.\r\n\r\n```js\r\nvar myWritableStreamBuffer = new streamBuffers.WritableStreamBuffer({\r\n\tinitialSize: (100 * 1024),   // start at 100 kilobytes.\r\n\tincrementAmount: (10 * 1024) // grow by 10 kilobytes each time buffer overflows.\r\n});\r\n```\r\n\r\nThe default initial size and increment amount are stored in the following constants:\r\n\r\n```js\r\nstreamBuffers.DEFAULT_INITIAL_SIZE      // (8 * 1024)\r\nstreamBuffers.DEFAULT_INCREMENT_AMOUNT  // (8 * 1024)\r\n```\r\n\r\nWriting is standard Stream stuff:\r\n\r\n```js\r\nmyWritableStreamBuffer.write(myBuffer);\r\n// - or -\r\nmyWritableStreamBuffer.write('\\u00bd + \\u00bc = \\u00be', 'utf8');\r\n```\r\n\r\nYou can query the size of the data being held in the Buffer, and also how big the Buffer's max capacity currently is: \r\n\r\n```js\r\nmyWritableStreamBuffer.write('ASDF');\r\nstreamBuffers.size();     // 4.\r\nstreamBuffers.maxSize();  // Whatever was configured as initial size. In our example: (100 * 1024).\r\n```\r\n\r\nRetrieving the contents of the Buffer is simple.\r\n\r\n```js\r\n// Gets all held data as a Buffer.\r\nmyWritableStreamBuffer.getContents();\r\n\r\n// Gets all held data as a utf8 string.\r\nmyWritableStreamBuffer.getContentsAsString('utf8');\r\n\r\n// Gets first 5 bytes as a Buffer.\r\nmyWritableStreamBuffer.getContents(5);\r\n\r\n// Gets first 5 bytes as a utf8 string.\r\nmyWritableStreamBuffer.getContentsAsString('utf8', 5);\r\n```\r\n\r\n**Care should be taken when getting encoded strings from WritableStream, as it doesn't really care about the contents (multi-byte characters will not be respected).**\r\n\r\nDestroying or ending the WritableStream will not delete the contents of Buffer, but will disallow any further writes.\r\n\r\n```js\r\nmyWritableStreamBuffer.write('ASDF');\r\nmyWritableStreamBuffer.end();\r\nmyWritableStreamBuffer.getContentsAsString(); // -> 'ASDF'\r\n```\t\r\n\r\n### ReadableStreamBuffer\r\n\r\n`ReadableStreamBuffer` implements the standard [`stream.Readable`](https://nodejs.org/api/stream.html#stream_class_stream_readable), but can have data inserted into it. This data will then be pumped out in chunks as readable events. The data to be sent out is held in a Buffer, which can grow in much the same way as a `WritableStreamBuffer` does, if data is being put in Buffer faster than it is being pumped out. \r\n\r\nThe frequency in which chunks are pumped out, and the size of the chunks themselves can be configured in the constructor. The initial size and increment amount of internal Buffer can be configured too. In the following example 2kb chunks will be output every 10 milliseconds:\r\n\r\n```js\r\nvar myReadableStreamBuffer = new streamBuffers.ReadableStreamBuffer({\r\n\tfrequency: 10,   // in milliseconds.\r\n\tchunkSize: 2048  // in bytes.\r\n});\r\n```\r\n\r\nDefault frequency and chunk size:\r\n\r\n```js\r\nstreamBuffers.DEFAULT_CHUNK_SIZE  // (1024)\r\nstreamBuffers.DEFAULT_FREQUENCY   // (1)\r\n```\r\n\r\nPutting data in Buffer to be pumped out is easy:\r\n\r\n```js\r\nmyReadableStreamBuffer.put(aBuffer);\r\nmyReadableStreamBuffer.put('A String', 'utf8');\r\n```\r\n\r\nChunks are pumped out via standard `stream.Readable` semantics. This means you can use the old streams1 way:\r\n\r\n```js\r\nmyReadableStreamBuffer.on('data', function(data) {\r\n  // streams1.x style data\r\n  assert.isTrue(data instanceof Buffer);\r\n});\r\n```\r\n\r\nOr the streams2+ way:\r\n\r\n```js\r\nmyReadableStreamBuffer.on('readable', function(data) {\r\n  var chunk;\r\n  while((chunk = myReadableStreamBuffer.read()) !== null) {\r\n    assert.isTrue(chunk instanceof Buffer);\r\n  }\r\n});\r\n```\r\n\r\nBecause `ReadableStreamBuffer` is simply an implementation of [`stream.Readble`](https://nodejs.org/api/stream.html#stream_class_stream_readable), it implements pause / resume / setEncoding / etc.\r\n\r\nOnce you're done putting data into a `ReadableStreamBuffer`, you can call `stop()` on it.\r\n\r\n```js\r\nmyReadableStreamBuffer.put('the last data this stream will ever see');\r\nmyReadableStreamBuffer.stop();\r\n```\r\n\r\nOnce the `ReadableStreamBuffer` is done pumping out the data in its internal buffer, it will emit the usual [`end`](https://nodejs.org/api/stream.html#stream_event_end) event. You cannot write any more data to the stream once you've called `stop()` on it.\r\n\r\n## Disclaimer\r\n\r\nNot supposed to be a speed demon, it's more for tests/debugging or weird edge cases. It works with an internal buffer that it copies contents to/from/around.\r\n\r\n## Contributors\r\n\r\nThanks to the following people for taking some time to contribute to this project.\r\n\r\n * Igor Dralyuk <idralyuk@ebay.com>\r\n * Simon Koudijs <simon.koudijs@intellifi.nl>\r\n\r\n## License\r\n\r\nnode-stream-buffer is free and unencumbered public domain software. For more information, see the accompanying UNLICENSE file.\r\n\r\n[badge-travis-img]: http://img.shields.io/travis/samcday/node-stream-buffer.svg?style=flat-square\r\n[badge-travis-url]: https://travis-ci.org/samcday/node-stream-buffer\r\n[badge-david-img]: https://img.shields.io/david/samcday/node-stream-buffer.svg?style=flat-square\r\n[badge-david-url]: https://david-dm.org/samcday/node-stream-buffer\r\n[badge-climate-img]: http://img.shields.io/codeclimate/github/samcday/node-stream-buffer.svg?style=flat-square\r\n[badge-climate-url]: https://codeclimate.com/github/samcday/node-stream-buffer\r\n[badge-coverage-img]: http://img.shields.io/codeclimate/coverage/github/samcday/node-stream-buffer.svg?style=flat-square\r\n[badge-coverage-url]: https://codeclimate.com/github/samcday/node-stream-buffer\r\n[badge-npm-img]: https://img.shields.io/npm/dm/stream-buffers.svg?style=flat-square\r\n[badge-npm-url]: https://www.npmjs.org/package/stream-buffers\r\n\r\n[node-buffer-docs]: http://nodejs.org/api/buffer.html\r\n",
  "readmeFilename": "README.md",
  "bugs": {
    "url": "https://github.com/samcday/node-stream-buffer/issues"
  },
  "homepage": "https://github.com/samcday/node-stream-buffer#readme",
  "_id": "stream-buffers@3.0.0",
  "_from": "stream-buffers@*"
}
